host: login01
Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job                     count
--------------------  -------
normalised_frequency        1
plot                        1
rescale                     1
total                       3

Select jobs to execute...
Execute 1 jobs...

[Thu Oct 24 20:09:16 2024]
localrule normalised_frequency:
    input: shuf.a.bed.gz
    output: query_unsorted.hist, query.hist
    jobid: 2
    reason: Missing output files: query.hist
    resources: tmpdir=/tmp

[Thu Oct 24 20:09:22 2024]
Finished job 2.
1 of 3 steps (33%) done
Removing temporary output query_unsorted.hist.
Select jobs to execute...
Execute 1 jobs...

[Thu Oct 24 20:09:22 2024]
localrule rescale:
    input: query.hist
    output: lines_to_pull.tsv, rescaled.hist
    jobid: 1
    reason: Missing output files: rescaled.hist; Input files updated by another job: query.hist
    resources: tmpdir=/tmp

[Thu Oct 24 20:09:22 2024]
Error in rule rescale:
    jobid: 1
    input: query.hist
    output: lines_to_pull.tsv, rescaled.hist
    shell:
        
        python scripts/lines.py > lines_to_pull.tsv
        cat lines_to_pull.tsv | python scripts/normalise.py > rescaled.hist
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job rescale since they might be corrupted:
lines_to_pull.tsv
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-10-24T200916.374032.snakemake.log
WorkflowError:
At least one job did not complete successfully.
