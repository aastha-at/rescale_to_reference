host: login01
Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job                     count
--------------------  -------
calculate_lines             1
normalised_frequency        1
subsample                   1
total                       3

Select jobs to execute...
Execute 1 jobs...

[Sun Oct 20 15:09:53 2024]
localrule normalised_frequency:
    input: shuf.a.bed.gz
    output: query_unsorted.hist, query_sorted.hist
    jobid: 2
    reason: Missing output files: query_sorted.hist
    resources: tmpdir=/tmp

[Sun Oct 20 15:09:59 2024]
Finished job 2.
1 of 3 steps (33%) done
Select jobs to execute...
Execute 1 jobs...

[Sun Oct 20 15:09:59 2024]
localrule calculate_lines:
    input: query_sorted.hist
    output: calculate_lines_to_pull.tsv
    jobid: 1
    reason: Missing output files: calculate_lines_to_pull.tsv; Input files updated by another job: query_sorted.hist
    resources: tmpdir=/tmp

[Sun Oct 20 15:09:59 2024]
Finished job 1.
2 of 3 steps (67%) done
Select jobs to execute...
Execute 1 jobs...

[Sun Oct 20 15:09:59 2024]
localrule subsample:
    input: shuf.a.bed.gz, calculate_lines_to_pull.tsv
    output: shuffled.bed.gz, output.bed.gz
    jobid: 0
    reason: Missing output files: output.bed.gz; Input files updated by another job: calculate_lines_to_pull.tsv
    resources: tmpdir=/tmp

[Sun Oct 20 15:10:32 2024]
Finished job 0.
3 of 3 steps (100%) done
Complete log: .snakemake/log/2024-10-20T150953.591424.snakemake.log
